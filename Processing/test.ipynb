{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 175954 entries, 0 to 4859\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   titre    175954 non-null  object\n",
      " 1   date     175954 non-null  object\n",
      " 2   extrait  175723 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "path = \"../Data collection/Historic data/raw data/\"\n",
    "files = glob.glob(path + \"/*.csv\") \n",
    "Datasets = pd.DataFrame()\n",
    "content = [pd.read_csv(filename, index_col=None) for filename in files]\n",
    "Datasets = pd.concat(content)\n",
    "\n",
    "Datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\PycharmProjects\\pythonProject1\\venv\\lib\\site-packages\\dateparser\\date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    }
   ],
   "source": [
    "def format_date(date):\n",
    "    return  dateparser.parse(str(date)).date()\n",
    "Datasets[\"date\"] = Datasets[\"date\"].apply(format_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets.to_csv(r\"C:\\Users\\hp\\Desktop\\PE\\Processing\\Outpout\\Datasets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>date</th>\n",
       "      <th>extrait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129915</th>\n",
       "      <td>Vidéo. Université d’été CGEM. Jean-Louis Borlo...</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>Dans une déclaration devant Le360, en marge de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60829</th>\n",
       "      <td>Air France relance ses vols vers trois villes...</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>Air France relance ses vols vers trois villes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160768</th>\n",
       "      <td>Première rencontre entre les opérateurs du tou...</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>\\nLa ministre du Tourisme a reçu, ce mardi 2 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170385</th>\n",
       "      <td>Maroc-Sénégal : Signature de sept accords et c...</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>\\nLe Roi Mohammed VI, accompagné du Prince Mou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107513</th>\n",
       "      <td>\"Il n’y a pas encore de découvertes de pétrole...</td>\n",
       "      <td>2014-03-14</td>\n",
       "      <td>\"Il n’y a pas encore de découvertes de pétrole...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    titre        date  \\\n",
       "129915  Vidéo. Université d’été CGEM. Jean-Louis Borlo...  2019-09-13   \n",
       "60829    Air France relance ses vols vers trois villes...  2020-08-18   \n",
       "160768  Première rencontre entre les opérateurs du tou...  2021-11-02   \n",
       "170385  Maroc-Sénégal : Signature de sept accords et c...  2013-07-26   \n",
       "107513  \"Il n’y a pas encore de découvertes de pétrole...  2014-03-14   \n",
       "\n",
       "                                                  extrait  \n",
       "129915  Dans une déclaration devant Le360, en marge de...  \n",
       "60829   Air France relance ses vols vers trois villes ...  \n",
       "160768  \\nLa ministre du Tourisme a reçu, ce mardi 2 n...  \n",
       "170385  \\nLe Roi Mohammed VI, accompagné du Prince Mou...  \n",
       "107513  \"Il n’y a pas encore de découvertes de pétrole...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_data=pd.read_csv(r\"C:\\Users\\hp\\Desktop\\PE\\Processing\\Outpout\\Datasets.csv\")\n",
    "formated_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titre      0\n",
       "date       0\n",
       "extrait    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert date column into datetima\n",
    "formated_data['date'] = pd.to_datetime(formated_data['date'], errors = 'coerce')\n",
    "\n",
    "# delete rows with null values\n",
    "formated_data.dropna(inplace=True)\n",
    "formated_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_data.to_csv(r\"Outpout\\Datasets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>date</th>\n",
       "      <th>extrait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transport – Royal Air Maroc, première compagni...</td>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>Le transporteur national, Royal Air Maroc (RAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Innovation – Maroc: 10 lauréats désignés lors ...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>Au Maroc, 10 lauréats ont été désignés lors de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classement – Tanger Med en 6è position dans la...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>Le Port de Tanger Med a été classé en 6è posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistics – Après deux années d’absence, Logis...</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>La 9ème édition du Salon international du tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coopération – Treize MoU d’entente portant sur...</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>Les travaux du Forum « Morocco-Israel: Connect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titre       date  \\\n",
       "0  Transport – Royal Air Maroc, première compagni... 2022-05-30   \n",
       "1  Innovation – Maroc: 10 lauréats désignés lors ... 2022-05-28   \n",
       "2  Classement – Tanger Med en 6è position dans la... 2022-05-28   \n",
       "3  Logistics – Après deux années d’absence, Logis... 2022-05-28   \n",
       "4  Coopération – Treize MoU d’entente portant sur... 2022-05-26   \n",
       "\n",
       "                                             extrait  \n",
       "0  Le transporteur national, Royal Air Maroc (RAM...  \n",
       "1  Au Maroc, 10 lauréats ont été désignés lors de...  \n",
       "2  Le Port de Tanger Med a été classé en 6è posit...  \n",
       "3  La 9ème édition du Salon international du tran...  \n",
       "4  Les travaux du Forum « Morocco-Israel: Connect...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\PE\\Processing\\Outpout\\Datasets.csv\", parse_dates=['date'])\n",
    "clean.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>date</th>\n",
       "      <th>extrait</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156585</th>\n",
       "      <td>\\nCovid-19: Une société marocaine se reconvert...</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>Casablanca -   \\r\\n     La société marocaine \"...</td>\n",
       "      <td>2020-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151049</th>\n",
       "      <td>Médecine: le privé déclare la guerre au public</td>\n",
       "      <td>2016-06-22</td>\n",
       "      <td>La guerre entre les médecins du public et du p...</td>\n",
       "      <td>2016-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>L’Office des changes accélère ses process digi...</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>Objectif : 95% des demandes d’autorisations vi...</td>\n",
       "      <td>2021-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81856</th>\n",
       "      <td>Maroc : forte hausse du déficit budgétaire</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>Maroc : forte hausse du déficit budgétaire Le ...</td>\n",
       "      <td>2019-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111171</th>\n",
       "      <td>La CGEM face aux défis et attentes des entrepr...</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>La Confédération générale des entreprises du M...</td>\n",
       "      <td>2019-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    titre       date  \\\n",
       "156585  \\nCovid-19: Une société marocaine se reconvert... 2020-04-21   \n",
       "151049     Médecine: le privé déclare la guerre au public 2016-06-22   \n",
       "7818    L’Office des changes accélère ses process digi... 2021-01-21   \n",
       "81856          Maroc : forte hausse du déficit budgétaire 2019-10-15   \n",
       "111171  La CGEM face aux défis et attentes des entrepr... 2019-12-28   \n",
       "\n",
       "                                                  extrait   period  \n",
       "156585  Casablanca -   \\r\\n     La société marocaine \"...  2020-04  \n",
       "151049  La guerre entre les médecins du public et du p...  2016-06  \n",
       "7818    Objectif : 95% des demandes d’autorisations vi...  2021-01  \n",
       "81856   Maroc : forte hausse du déficit budgétaire Le ...  2019-10  \n",
       "111171  La Confédération générale des entreprises du M...  2019-12  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean['period']=clean['date'].dt.to_period('M')\n",
    "clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_M_Y = clean.groupby('period')['extrait'].apply(list)\n",
    "periods = clean.period.unique().tolist()\n",
    "extraits_grouped = grouped_by_M_Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-11-22 00:00:00')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpuses = [ corpus=lower_text(corpus) for corpus in extraits_grouped]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some text mining functions for processing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "np.set_printoptions(precision=2, linewidth=80)\n",
    "# from nltk import FreqDist\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "#from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "spacy.load('fr_core_news_md')\n",
    "import fr_core_news_md #import spacy french stemmer\n",
    "from sklearn.decomposition import NMF,LatentDirichletAllocation\n",
    "\n",
    "import pyLDAvis #Nous utilisons pyLDAvis pour créer des visualisations interactives de modèles de sujet.\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "#dealing with date\n",
    "import dateparser\n",
    "\n",
    "#output French accents correctly\n",
    "def convert_accents(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore')\n",
    "\n",
    "\n",
    "#convertisse les documents en minuscule\n",
    "def lower_text(corpus):\n",
    "    LowerCorpus=[]\n",
    "    for doc in corpus:\n",
    "        lowerDoc=str(doc).lower() #convertissent le texte en minuscules\n",
    "        lowerDoc=convert_accents(lowerDoc).decode(\"utf-8\") #supprimes les accents\n",
    "        LowerCorpus.append(lowerDoc)\n",
    "    return LowerCorpus\n",
    "\n",
    "\n",
    "def remove_characters(corpus,keep_apostrophes=True):\n",
    "    filtered_corpus=[]\n",
    "    for doc in corpus:\n",
    "        doc = doc.strip()\n",
    "        if keep_apostrophes:\n",
    "            doc =re.sub('(https|http)\\S*\\s?', '',doc) #supprimes les urls\n",
    "            PATTERN = r'[?|$|&|*|%|@|(|)|~|\\d]'\n",
    "            filtered_doc = re.sub(PATTERN, r'', doc)\n",
    "            filtered_corpus.append(filtered_doc)\n",
    "        else:\n",
    "            PATTERN = r'[^a-zA-Z ]'\n",
    "            #supprimes les urls\n",
    "            doc =re.sub('(https|http)\\S*\\s?', '',doc) #supprimes les urls\n",
    "            filtered_doc = re.sub(PATTERN, r'', doc)\n",
    "        \n",
    "            filtered_corpus.append(filtered_doc)\n",
    "    return filtered_corpus\n",
    "\n",
    "\n",
    "#Tokenization\n",
    "def tokenize_text(corpus):\n",
    "    tokensCorpus=[]\n",
    "    for doc in corpus:\n",
    "        doc_tokens = word_tokenize(doc)\n",
    "        tokensCorpus.append(doc_tokens)\n",
    "    return tokensCorpus\n",
    "\n",
    "\n",
    "#recuperer les mots qui apparaissent dans plusieurs documents\n",
    "def get_mostCommonWords(corpus,max_freq=100):\n",
    "    vocabulaire=dict() #dictionnaire qui va contenir le nombre d'occurence des mots dans les documents\n",
    "    for doc in corpus:\n",
    "        for word in set(doc.split()): #recupere les mots unique de chaque documents\n",
    "            if word in vocabulaire:\n",
    "                vocabulaire[word]+=1\n",
    "            else:\n",
    "                vocabulaire[word]=1\n",
    "    \n",
    "    #recupere les dont le nombre d'occurences dans les documents > max_freq\n",
    "    mostCommonsWord=[word for word,value in vocabulaire.items() if value>max_freq ]\n",
    "        \n",
    "    return mostCommonsWord\n",
    "\n",
    "\n",
    "# removing stopwords\n",
    "def remove_stopwords(corpus,mostCommonsWord):\n",
    "    filtered_corpus=[]\n",
    "    for tokens in corpus:\n",
    "        others_sw=[\"maroc\",\"morocco\",\"marocain\",\"marocaine\",\"marocains\",\"marocaines\",\"maghreb\",\"météorologique\",\"journée\",\n",
    "                   \"méteo\",\"retweet\",\"newspic\",\"twitter\",\"com\",\"pic\",\"newspic\",\"illustration\"]\n",
    "        \n",
    "        #french_sw = stopwords.words('french') \n",
    "        french_sw=list(STOP_WORDS) #get french stopwords\n",
    "        french_sw.extend(others_sw)\n",
    "        french_sw.extend(mostCommonsWord)\n",
    "        \n",
    "        filtered_tokens = [token for token in tokens.split() if token not in french_sw and len(token)>2]\n",
    "        filtred_text=' '.join(filtered_tokens) #reforme le text du documents separé par espace\n",
    "        filtered_corpus.append(filtred_text)\n",
    "    return filtered_corpus\n",
    "\n",
    "\n",
    "#lemmatisation\n",
    "def lemm_tokens(corpus):\n",
    "    \n",
    "    nlp = fr_core_news_md.load() #initialisation du model \"fr_core_news_md\" de spacy\n",
    "    allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "    corpus_lemms=[]\n",
    "    \n",
    "    idx_doc=[] #liste qui va stocker les indices documents qui seront dans le corpus\n",
    "    for idx,document in enumerate(corpus):\n",
    "        doc = nlp(document)\n",
    "        lemms=[token.lemma_ for token in doc if token.pos_ in allowed_postags] #recupere les lemms des tokens\n",
    "        \n",
    "        if len(lemms)>5: #supprime les document qui ne contient pas plus de 2 mots\n",
    "            text=' '.join(lemms) #reforme le text du documents separé par espace\n",
    "            corpus_lemms.append(text)\n",
    "            idx_doc.append(idx) #ajoute l'indice du documents\n",
    "            \n",
    "    return corpus_lemms,idx_doc\n",
    "\n",
    "\n",
    "#fonction qui supprimes les documents vides ou tres courte\n",
    "def remove_shortDocument(corpus,min_length=3):\n",
    "    filtred_corpus=[]\n",
    "    idx_doc=[]\n",
    "    for idx,doc in enumerate(corpus):\n",
    "        \n",
    "        if len(doc.split())>min_length:\n",
    "            filtred_corpus.append(doc)\n",
    "            idx_doc.append(idx)\n",
    "        \n",
    "    \n",
    "    return filtred_corpus,idx_doc\n",
    "\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    bigram = gensim.models.Phrases(texts, min_count=2, threshold=10) # higher threshold fewer phrases\n",
    "    # Un moyen plus rapide d'obtenir une phrase matraquée comme un trigramme / bigramme\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    corpus_bigram=[\" \".join(bigram_mod[doc]) for doc in texts]\n",
    "    return corpus_bigram\n",
    "\n",
    "\n",
    "def preprocessing(corpus):\n",
    "    \n",
    "    corpus=lower_text(corpus)\n",
    "    corpus=remove_characters(corpus)\n",
    "    corpus=tokenize_text(corpus)\n",
    "    #corpus=remove_mostCommonWords(corpus,max_freq=20)\n",
    "    corpus=remove_stopwords(corpus)\n",
    "    corpus,idx_docs=lemm_tokens(corpus)\n",
    "    \n",
    "    \n",
    "    return corpus,idx_docs\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19084cb2a221719542bd94e588e69917ee95725b301fa5f2df470f319dde6836"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
